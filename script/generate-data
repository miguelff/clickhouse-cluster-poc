#!/usr/bin/env ruby
require 'csv'
require 'securerandom'

class Generator
  attr_reader :projects, :queries, :start

  def initialize(args={})
    @start = args[:start] || Time.now

    num_projects = args[:num_projects] || 1
    @projects = [].tap do |p|
      num_projects.times do
        p << random_uuid
      end
    end
  end

  def generate(count=100, args={})
    [].tap do |rows|
      count.times do |r|
        rows << generate_row(args.merge("row" => r))
      end
    end
  end

  def timestamp(start, offset)
    (start + offset).strftime("%Y-%m-%d %H:%M:%S")
  end

  def nullable(prob=0.1)
    return yield if rand > prob
  end

  def random_string(length=8)
    (0...length).map { (65 + rand(26)).chr }.join
  end

  def random_uuid
    SecureRandom.uuid
  end

  def self.nil_methods(*args)
    args.each do |a|
      define_method(a) {}
    end
  end
end

class OperationLogsGenerator < Generator

  attr_reader :queries

  def initialize(args={})
    super
    num_queries = args[:num_queries] || 1
    @queries = [].tap do |p|
      num_queries.times do
          p << {hash: random_string, operation_type: nullable{ random_string }, operation_name: %w(query mutation).sample, operation_id: nullable{ random_string }, query: nullable(0.1) { random_string(50)} }
      end
    end
  end

  def generate_row(args)
    offset = (args["row"] || 0) / (args["rps"]&.to_i || 10)
    start = Time.now
    query = queries.sample
    [
        projects.sample,
        timestamp(start, offset),
        request_id,
        server_client_id,
        instance_uid,
        client_name,
        query[:operation_type],
        query[:operation_name],
        query[:operation_id],
        transport,
        role,
        query[:query],
        query[:hash],
        session_vars,
        request_size,
        response_size,
        latency,
        request_read_time,
        error,
        error_code,
        http_info,
        websocket_id,
        ws_operation_id,
        opkind,
        generated_sql,
    ]
  end

  nil_methods(:error_code, :http_info, :websocket_id, :ws_operation_id, :opkind, :generated_sql)

  def latency
    rand(1000...1_000_000)
  end
  alias_method :request_read_time, :latency

  def request_size
    nullable(0.1) { rand(1..1000) }
  end

  def response_size
    nullable(0.1) { rand(1..1000) }
  end

  def session_vars
    '{}'
  end

  def error
    nullable(0.9) { random_string }
  end

  def client_name
    nullable { random_string }
  end

  def request_id
    random_string(10)
  end

  def server_client_id
    nullable { random_string }
  end

  def transport
    %w(http ws).sample
  end

  def role
    %w(user admin worker).sample
  end

  def parameterized_query_hash
    random_string(40)
  end

  def instance_uid
    random_uuid
  end
end

if $0 == __FILE__
  require 'open3'
  args = Hash[ARGV.join(' ').scan(/--?([^=\s]+)(?:=(\S+))?/) ]
  args["table"] ||= "operation_logs"
  args["projects"] ||= 10
  args["queries"] ||= 100
  args["rows"] ||= 200000
  args["container"] ||= "clickhouse-s1-r1"
  args["csv-only"] ||= false
  args["rps"] ||= 1000

  puts "DEBUG: Generating csv: #{args.inspect}"

  generator = case args["table"]
              when "operation_logs"
                OperationLogsGenerator
              end

  csv = generator.new(num_projects: args.delete("projects").to_i, num_queries: args.delete("queries").to_i).generate(args.delete("rows").to_i, args).map(&:to_csv).join()

  if args["csv-only"]
  	puts "DEBUG: \n"+ csv
  	exit
  end

  cmd = "docker exec -i #{args["container"]} clickhouse-client --query=\"INSERT INTO analytics.#{args["table"]} FORMAT CSV\""
  puts "DEBUG: Running Command: #{cmd}"

  Open3.popen3(cmd) do |i,o,e,t|
    i.write csv
    i.close
    puts o.read
    STDERR.puts e.read
  end
end


